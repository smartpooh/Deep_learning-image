{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boiler Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T19:39:04.967915Z",
     "start_time": "2019-01-23T19:39:04.681156Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T19:39:05.986325Z",
     "start_time": "2019-01-23T19:39:05.741758Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Step1: Image Face finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:19:26.867159Z",
     "start_time": "2019-01-22T21:19:24.929580Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Importing image using open cv\n",
    "img = cv2.imread('Aayush Agrawal1.jpg',1)\n",
    "\n",
    "## Resizing to constant width\n",
    "img = imutils.resize(img, width=300)\n",
    "\n",
    "## Converting BGR to RGB\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## Taken from https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "face_coord = face_cascade.detectMultiScale(gray,1.2,10,minSize=(30,30))\n",
    "\n",
    "img_cp = img.copy()\n",
    "for coords in face_coord:\n",
    "    X, Y, w, h = coords\n",
    "    cv2.rectangle(\n",
    "        img = img_cp, \n",
    "        pt1 = (X - int(w*0.1), Y - int(0.35*h)), \n",
    "        pt2 = (X + int(1.1*w), Y + int(1.1*h)), \n",
    "        color=(0, 0, 255), \n",
    "        thickness=2\n",
    "    )\n",
    "    \n",
    "cv2.imshow('image',img_cp)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T21:21:33.464678Z",
     "start_time": "2019-01-22T21:21:33.353093Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 207, 3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[Y - int(0.35*h):Y + int(1.1*h),X - int(w*0.1):X + int(1.1*w)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T15:28:00.011028Z",
     "start_time": "2019-01-18T15:27:59.598036Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Step2: Video Face Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T20:37:27.752985Z",
     "start_time": "2019-01-22T20:37:27.517479Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Taken from https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T20:37:45.173725Z",
     "start_time": "2019-01-22T20:37:28.823488Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    ## Resizing to constant width\n",
    "    img = imutils.resize(frame, width=300)\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Find faces using Haar cascade\n",
    "    face_coord = face_cascade.detectMultiScale(gray,1.1,5,minSize=(30,30))\n",
    "    \n",
    "    for coords in face_coord:\n",
    "        X, Y, w, h = coords\n",
    "        cv2.rectangle(img=frame, pt1=(X, Y), pt2=(X + w, Y + h), color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T22:06:24.635596Z",
     "start_time": "2019-01-22T22:06:24.482778Z"
    }
   },
   "outputs": [],
   "source": [
    "## !kaggle datasets download -d jessicali9530/celeba-datasetb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting frontal face from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Haar Cascade\n",
    "## Taken from https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-22T22:10:50.325750Z",
     "start_time": "2019-01-22T22:10:50.177489Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_extractor(origin, destination, fc):\n",
    "    ## Importing image using open cv\n",
    "    img = cv2.imread(origin,1)\n",
    "\n",
    "    ## Resizing to constant width\n",
    "    img = imutils.resize(img, width=200)\n",
    "    H,W,_ = img.shape\n",
    "    ## Converting BGR to RGB\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## Detecting faces on the image\n",
    "    face_coord = fc.detectMultiScale(gray,1.2,10,minSize=(50,50))\n",
    "    \n",
    "    if len(face_coord) == 1:\n",
    "        X, Y, w, h = face_coord[0]\n",
    "    \n",
    "    elif len(face_coord)==0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        max_val = 0\n",
    "        max_idx = 0\n",
    "        for idx in range(len(face_coord)):\n",
    "            _, _, w_i, h_i = face_coord[idx]\n",
    "            if w_i*h_i > max_val:\n",
    "                max_idx = idx\n",
    "                max_val = w_i*h_i\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            X, Y, w, h = face_coord[max_idx]\n",
    "            \n",
    "    img_cp = img[\n",
    "            max(0,Y - int(0.35*h)): min(Y + int(1.35*h), H),\n",
    "            max(0,X - int(w*0.35)): min(X + int(1.35*w), W)\n",
    "        ].copy()\n",
    "    \n",
    "    cv2.imwrite(destination, img_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T15:18:37.479075Z",
     "start_time": "2019-01-23T15:18:37.302071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202599\n"
     ]
    }
   ],
   "source": [
    "path = '../data/celeba-dataset/faces/'\n",
    "item_list = glob.glob('../data/celeba-dataset/img_align_celeba/*.jpg')\n",
    "print(len(item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T00:42:26.515713Z",
     "start_time": "2019-01-22T22:12:22.334078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fd559e3adc44088e677985156dd005"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for org in tqdm_notebook(item_list):\n",
    "    face_extractor(origin = org, destination = path+org.split('\\\\')[1], fc=face_cascade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T19:36:12.416672Z",
     "start_time": "2019-01-23T19:36:12.272555Z"
    }
   },
   "source": [
    " list_eval_partition.csv: Recommended partitioning of images into training, validation, testing sets. Images 1-162770 are training, 162771-182637 are validation, 182638-202599 are testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T19:37:18.102476Z",
     "start_time": "2019-01-23T19:37:16.879695Z"
    }
   },
   "outputs": [],
   "source": [
    "item_list = glob.glob('../data/celeba-dataset/faces/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T20:31:15.535405Z",
     "start_time": "2019-01-23T19:44:25.147656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dc8cdfadcb4879b0c84921a0acbf7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm_notebook(range(1,202600)):\n",
    "    if idx <= 182637:\n",
    "        destination = path+'training/'\n",
    "    else:\n",
    "        destination = path+'validation/'\n",
    "    try:\n",
    "        shutil.move(\n",
    "            path+str(idx).zfill(6)+'.jpg', \n",
    "            destination+str(idx).zfill(6)+'.jpg'\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:02:58.586397Z",
     "start_time": "2019-01-23T21:59:06.650539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a636daef555c4582916e627588bc048f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_df = pd.read_csv('../data/celeba-dataset/list_attr_celeba.csv')\n",
    "column_list = pd.Series(list(label_df.columns)[1:])\n",
    "\n",
    "def label_generator(row):\n",
    "    return(' '.join(column_list[[True if i==1 else False for i in row[column_list]]]))\n",
    "\n",
    "label_df['label'] = label_df.progress_apply(lambda x: label_generator(x), axis=1)\n",
    "label_df = label_df.loc[:,['image_id','label']]\n",
    "label_df.to_csv('../data/celeba-dataset/labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:26:34.524641Z",
     "start_time": "2019-01-23T22:26:32.615235Z"
    }
   },
   "outputs": [],
   "source": [
    "item_list = glob.glob('../data/celeba-dataset/faces/*/*.jpg')\n",
    "item_df = pd.DataFrame({'image_name':pd.Series(item_list).apply(lambda x: '/'.join(x.split('\\\\')[1:]))})\n",
    "item_df['image_id'] = item_df.image_name.apply(lambda x: x.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:28:23.153561Z",
     "start_time": "2019-01-23T22:28:21.617736Z"
    }
   },
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('../data/celeba-dataset/labels.csv')\n",
    "label_df = label_df.merge(item_df, on='image_id', how='inner')\n",
    "label_df.rename(columns={'label':'tags'}, inplace=True)\n",
    "label_df.loc[:,['image_name','tags']].to_csv('../data/celeba-dataset/faces/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T21:25:20.101766Z",
     "start_time": "2019-01-23T21:25:18.745322Z"
    }
   },
   "source": [
    "## Creating data bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:28:49.182564Z",
     "start_time": "2019-01-23T22:28:48.721023Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "path = Path('../data/celeba-dataset/faces/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:28:50.456530Z",
     "start_time": "2019-01-23T22:28:49.293318Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/celeba-dataset/faces/labels.csv')\n",
    "def validation_func(x):\n",
    "    return 'validation' in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:45:10.757323Z",
     "start_time": "2019-01-23T22:45:10.115320Z"
    }
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=False, flip_vert=False, max_rotate=30, max_lighting=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-23T22:45:22.579871Z",
     "start_time": "2019-01-23T22:45:11.569334Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (ImageItemList.from_csv(path, csv_name='labels.csv')\n",
    "       .split_by_valid_func(validation_func)\n",
    "       .label_from_df(label_delim=' ')\n",
    "       .transform(tfms, size=200)\n",
    "       .databunch().normalize(imagenet_stats))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3k]",
   "language": "python",
   "name": "conda-env-py3k-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
