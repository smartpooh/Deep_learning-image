{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to build a neural network(multilayer perceptron) using TensorFlow and successfully train it to recognize digits in the image. Tensorflow is a very popular deep learning framework released by, and this notebook will guide for build a neural network with this library. If you want to understand what is a Multi-layer perceptron, you can look at my [previous notebook](https://github.com/aayushmnit/Deep_learning_explorations/blob/master/1_MLP_from_scratch/Building_neural_network_from_scratch.ipynb) where I built a Multi-layer perceptron from scratch using numpy. <br/>\n",
    "Let's start by importing our data. As keras, a high-level deep learning library already has MNIST as part of their default data we are just going to import the dataset from there and split it into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T19:44:21.878591-05:00",
     "start_time": "2018-06-08T19:44:19.596690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ce5676d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loading MNIST dataset from keras\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_dataset(flatten=False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # normalize x\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "\n",
    "    # we reserve the last 10000 training examples for validation\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "## Printing dimensions\n",
    "print(X_train.shape, y_train.shape)\n",
    "## Visualizing the first digit\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our current data have dimension N * 28*28, we will start by flattening the image in N*784, and one-hot encode our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T19:48:49.676086-05:00",
     "start_time": "2018-06-08T19:48:49.652151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(50000, 784)\n",
      "Test dimension:\n",
      "(10000, 784)\n",
      "Train labels dimension:\n",
      "(50000, 10)\n",
      "Test labels dimension:\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "## Changing dimension of input images from N*28*28 to  N*784\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "\n",
    "## Changing labels to one-hot encoded vector\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print('Train labels dimension:');print(y_train.shape)\n",
    "print('Test labels dimension:');print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have processed the data, let's start building our multi-layer perceptron using tensorflow. We will begin by importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T19:53:33.413023-05:00",
     "start_time": "2018-06-08T19:53:20.057677Z"
    }
   },
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "s = tf.InteractiveSession() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_tf.InteractiveSession()_ is a way to run tensorflow model directly without instantiating a graph whenever we want to run a model. We will be building 784(Input)-512(Hidden layer 1)-256(Hidden layer 2)-10(Output) neural net model. Let's start our model construction by defining initialization variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:01:07.682313-05:00",
     "start_time": "2018-06-08T20:01:07.677315Z"
    }
   },
   "outputs": [],
   "source": [
    "## Defining various initialization parameters for 784-512-256-10 MLP model\n",
    "num_classes = y_train.shape[1]\n",
    "num_features = X_train.shape[1]\n",
    "num_output = y_train.shape[1]\n",
    "num_layers_0 = 512\n",
    "num_layers_1 = 256\n",
    "starter_learning_rate = 0.001\n",
    "regularizer_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tensorflow, we define a placeholder for our input variables and output variables and any variables we want to keep track of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:11:09.679237-05:00",
     "start_time": "2018-06-08T20:11:09.662284Z"
    }
   },
   "outputs": [],
   "source": [
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n",
    "input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n",
    "## for dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As dense layers require weights and biases and they need to be initialized with a random normal distribution with zero mean and small variance (1/square root of the number of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:11:12.098828-05:00",
     "start_time": "2018-06-08T20:11:12.061873Z"
    }
   },
   "outputs": [],
   "source": [
    "## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n",
    "weights_0 = tf.Variable(tf.random_normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n",
    "bias_0 = tf.Variable(tf.random_normal([num_layers_0]))\n",
    "\n",
    "weights_1 = tf.Variable(tf.random_normal([num_layers_0,num_layers_1], stddev=(1/tf.sqrt(float(num_layers_0)))))\n",
    "bias_1 = tf.Variable(tf.random_normal([num_layers_1]))\n",
    "\n",
    "weights_2 = tf.Variable(tf.random_normal([num_layers_1,num_output], stddev=(1/tf.sqrt(float(num_layers_1)))))\n",
    "bias_2 = tf.Variable(tf.random_normal([num_output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:12:01.441955-05:00",
     "start_time": "2018-06-08T20:12:01.436952Z"
    }
   },
   "source": [
    "Now we will start writing the graph calculation to develop our _784(Input)-512(Hidden layer 1)-256(Hidden layer 2)-10(Output) model_. We will multiply the input for each layer with its respective weights and add bias term. After weights and biases, we need to add an activation; we will use ReLU activation for hidden layers and softmax for the final output layer to get class probability score. Also to prevent overfitting; let 's add some drop out after each hidden layer. Dropout is an essential concept in creating redundancies in our network which leads to better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:22:16.493632-05:00",
     "start_time": "2018-06-08T20:22:16.468706Z"
    }
   },
   "outputs": [],
   "source": [
    "## Initializing weigths and biases\n",
    "hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights_0)+bias_0)\n",
    "hidden_output_0_0 = tf.nn.dropout(hidden_output_0, keep_prob)\n",
    "\n",
    "hidden_output_1 = tf.nn.relu(tf.matmul(hidden_output_0_0,weights_1)+bias_1)\n",
    "hidden_output_1_1 = tf.nn.dropout(hidden_output_1, keep_prob)\n",
    "\n",
    "predicted_y = tf.sigmoid(tf.matmul(hidden_output_1_1,weights_2) + bias_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define a loss function to optimize our weights and biases, and we will use softmax cross entropy with logits for the predicted and correct label. We will also add some L2 regularization to our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T20:24:24.433830-05:00",
     "start_time": "2018-06-08T20:24:24.408871Z"
    }
   },
   "outputs": [],
   "source": [
    "## Defining the loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_y,labels=input_y)) \\\n",
    "        + regularizer_rate*(tf.reduce_sum(tf.square(bias_0)) + tf.reduce_sum(tf.square(bias_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to define an optimizer and learning rate for our network to optimize weights and biases on our given loss function. We will use exponential decay on our learning rate by every five epoch to reduce the learning by 15%. For optimizer, we are going to use Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable learning rate\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n",
    "## Adam optimzer for finding the right weight\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,weights_2,\n",
    "                                                                         bias_0,bias_1,bias_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done with our model construction. Let's define accuracy metric to evaluate our model performance as loss function is non-intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T09:16:18.541806-05:00",
     "start_time": "2018-05-11T09:16:18.516686Z"
    }
   },
   "outputs": [],
   "source": [
    "## Metrics definition\n",
    "correct_prediction = tf.equal(tf.argmax(y_train,1), tf.argmax(predicted_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start training our network on train data and evaluate our network on test dataset simultaneously. We will be using batch optimization with size 128 and train it for 14 epochs to get 98%+ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T09:17:49.182212-05:00",
     "start_time": "2018-05-11T09:17:12.678519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Train loss: 40.71 Train acc: 0.936, Test acc:0.935\n",
      "Epoch:1, Train loss: 22.14 Train acc: 0.956, Test acc:0.954\n",
      "Epoch:2, Train loss: 12.20 Train acc: 0.966, Test acc:0.963\n",
      "Epoch:3, Train loss: 6.90 Train acc: 0.973, Test acc:0.968\n",
      "Epoch:4, Train loss: 4.12 Train acc: 0.977, Test acc:0.970\n",
      "Epoch:5, Train loss: 2.71 Train acc: 0.981, Test acc:0.973\n",
      "Epoch:6, Train loss: 2.02 Train acc: 0.982, Test acc:0.975\n",
      "Epoch:7, Train loss: 1.70 Train acc: 0.985, Test acc:0.975\n",
      "Epoch:8, Train loss: 1.56 Train acc: 0.985, Test acc:0.976\n",
      "Epoch:9, Train loss: 1.50 Train acc: 0.987, Test acc:0.979\n",
      "Epoch:10, Train loss: 1.48 Train acc: 0.989, Test acc:0.978\n",
      "Epoch:11, Train loss: 1.47 Train acc: 0.988, Test acc:0.976\n",
      "Epoch:12, Train loss: 1.47 Train acc: 0.989, Test acc:0.980\n",
      "Epoch:13, Train loss: 1.47 Train acc: 0.990, Test acc:0.980\n"
     ]
    }
   ],
   "source": [
    "## Training parameters\n",
    "batch_size = 128\n",
    "epochs=14\n",
    "dropout_prob = 0.6\n",
    "\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):    \n",
    "    arr = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "        s.run(optimizer, {input_X: X_train[arr[index:index+batch_size]],\n",
    "                          input_y: y_train[arr[index:index+batch_size]],\n",
    "                        keep_prob:dropout_prob})\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:X_train, \n",
    "                                                         input_y: y_train,keep_prob:1}))\n",
    "    training_loss.append(s.run(loss, {input_X: X_train, \n",
    "                                      input_y: y_train,keep_prob:1}))\n",
    "    \n",
    "    ## Evaluation of model\n",
    "    testing_accuracy.append(accuracy_score(y_test.argmax(1), \n",
    "                            s.run(predicted_y, {input_X: X_test,keep_prob:1}).argmax(1)))\n",
    "    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}, Test acc:{3:.3f}\".format(epoch,\n",
    "                                                                    training_loss[epoch],\n",
    "                                                                    training_accuracy[epoch],\n",
    "                                                                   testing_accuracy[epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualization train and test accuracy as a function of the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T09:20:21.231302-05:00",
     "start_time": "2018-05-11T09:20:21.104186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCTB+ZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d19a146898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.99\n",
      "Test Accuracy:0.98\n"
     ]
    }
   ],
   "source": [
    "## Plotting chart of training and testing accuracy as a function of iterations\n",
    "iterations = list(range(epochs))\n",
    "plt.plot(iterations, training_accuracy, label='Train')\n",
    "plt.plot(iterations, testing_accuracy, label='Test')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()\n",
    "print(\"Train Accuracy: {0:.2f}\".format(training_accuracy[-1]))\n",
    "print(\"Test Accuracy:{0:.2f}\".format(testing_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have successfully trained a Multi-Layer perceptron which was written in tensorflow with high validation accuracy!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
